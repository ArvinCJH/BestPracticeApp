package com.liyafeng.video;

public class Video {


    /**
     * 视频入门指南
     * https://zhuanlan.zhihu.com/p/28518637 （七牛音视频架构师）
     * ===================3gp================
     * 3GP是一种多媒体单元格式，由Third Generation Partnership Project（3GPP）定义，主要用于3G手机上。
     * 3GP是 MPEG-4 第12部分，又被称为MPEG-4/JPEG2000基本媒体文件格式
     * 3GP是MPEG-4 Part 14（MP4）的一种简化版本，减少了存储空间和较低的带宽需求，
     * 让手机上有限的存储空间可以使用。
     * 3GP文件视频的部分可以用MPEG-4 Part 2、H.263或MPEG-4 Part 10 (AVC/H.264)等格式来存储，
     * 声音的部分则支持AMR-NB、AMR-WB、AMR-WB+、AAC-LC或HE-AAC来当作声音的编码。
     * <p>
     * --------------------------
     * 3gp是一种容器，除了头部的视频信息外，还包括编码后的视频信息，而且支持多种编码方式
     * 很显然头部信息包含了编码方式。而且播放器的原理都是一样的，取出文件的头部信息
     * 然后将视频信息解码，然后播放
     * <p>
     *
     * <p>
     * =======================mp4=========================
     * MP4或称MPEG-4第14部分（英语：MPEG-4 Part 14）是一种标准的数字多媒体容器格式
     * 注意是容器格式
     * ---------------------------------
     * 同时拥有音频視频的MPEG-4文件通常使用标准扩展名.mp4
     * 仅有音频的MPEG-4文件会使用.m4a扩展名
     * <p>
     * * http://www.infoq.com/cn/articles/improving-android-video-on-news-feed-with-litho
     * * Facebook构建高性能Android视频组件实践之路
     *
     * @param args
     */
    public static void main(String[] args) {

    }

    /**
     * https://m.huxiu.com/article/263561.html （从.JPG到.AVI：视频编码最强入门科普）
     * <p>
     * <p>
     * ============基础知识============
     * <p>
     * ---------像素（图像的元素）-----------------
     * 像素点的英文叫Pixel（缩写为PX）。这个单词是由 Picture(图像) 和 Element（元素）这两个单词的字母所组成的。
     * <p>
     * 像素是图像显示的基本单位。我们通常说一幅图片的大小，例如是1920×1080，就是长度为1920个像素点，宽度为1080个像素点。
     * 乘积是2,073,600，也就是说，这个图片是两百万像素的。
     * 1920×1080，这个也被称为这幅图片的分辨率
     * <p>
     * ---------ppi------------
     * PPI，就是“Pixels Per Inch”，每英寸像素数。也就是，手机（或显示器）屏幕上每英寸面积，到底能放下多少个“像素点”。
     * 这个值当然是越高越好啦！PPI越高，图像就越清晰细腻。
     * <p>
     * 以前的功能机，例如诺基亚，屏幕PPI都很低，有很强烈的颗粒感
     * 后来，苹果开创了史无前例的“视网膜”（Retina）屏幕，PPI值高达326（每英寸屏幕有326像素），画质清晰，再也没有了颗粒感
     * <p>
     * -------------rgb-------------
     * 任何颜色，都可以通过红色（Red）、绿色（Green）、蓝色（Blue）按照一定比例调制出来。这三种颜色，被称为“三原色”。
     * 在计算机里，R、G、B也被称为“基色分量”。它们的取值，分别从0到255，一共256个等级
     * 256×256×256=16,777,216种，因此也简称为1600万色。
     * <p>
     * 256是2的8次方，所以最少一个8位的二进制就能表示256个数，所以三个颜色有占用内存的24位
     * 因此，这种方式表达出来的颜色，也被称为24位色。
     * <p>
     * 所以这种表示1一个像素点占用24bit内存
     * <p>
     * ------------帧率（Frame Rate）--------------
     * 在视频中，一个帧（Frame）就是指一幅静止的画面。帧率，
     * 就是指视频每秒钟包括的画面数量（FPS，Frame per second）。
     * 帧率越高，视频就越逼真、越流畅。
     */
    public void f1() {
    }


    /**
     * ==================视频采集===============
     * <p>
     * ------------摄像头工作原理-----------
     * https://www.cnblogs.com/fjutacm/p/220631977df995512d136e4dbd411951.html （camera理论基础和工作原理）
     * <p>
     * 光线通过镜头进入摄像头内部，然后经过IR Filter过滤红外光，最后到达sensor（传感器），
     * senor分为按照材质可以分为CMOS和CCD两种，可以将光学信号转换为电信号，
     * 再通过内部的ADC电路转换为数字信号，
     * 然后传输给DSP（如果有的话，如果没有则以DVP的方式传送数据到基带芯片baseband，此时的数据格式Raw Data，后面有讲进行加工）加工处理，
     * 转换成RGB、YUV等格式输出
     * <p>
     * 摄像头模组，Camera Compact Module，简写为CCM，是影响捕捉的重要元器件，我的理解就是硬件上的摄像头
     * 1.镜头
     * 一般由几片透镜组成透镜结构，按材质可分为塑胶透镜(plastic)或玻璃透镜(glass)
     * 透镜越多，成本越高，相对成像效果会更出色（个人理解是光线更均匀、更细致；对光线的选通更丰富；成像畸变更小，但是会导致镜头变长，光通量变小）。
     * 2.红外滤光片 IR Filter
     * 主要是过滤掉进入镜头的光线中的红外光，这是因为人眼看不到红外光，但是sensor却能感受到红外光，所以需要将光线中的红外光滤掉，以便图像更接近人眼看到的效果
     * <p>
     * 3.传感器 Sensor
     * sensor是摄像头的核心，负责将通过Lens的光信号转换为电信号，再经过内部AD转换为数字信号。
     * 每个pixel像素点只能感受R、G、B中的一种，因此每个像素点中存放的数据是单色光，
     * 所以我们通常所说的30万像素或者130万像素，表示的就是有30万或130万个感光点，
     * 每个感光点只能感应一种光，这些最原始的感光数据我们称为RAW Data。
     * Raw Data数据要经过ISP（应该理解为Image Sensor Processor，是Sensor模块的组成部分，下面有解释）的处理才能还原出三原色，
     * 也就是说如果一个像素点感应为R值，那么ISP会根据该感光点周围的G、B的值，
     * 通过插值和特效处理等，计算出该R点的G、B值，这样该点的RGB就被还原了，除此之外，ISP还有很多操作，
     * <p>
     * >>CCD（Charge Coupled Device），电荷耦合器件传感器：使用一种高感光度的半导体材料制成，能把光线转变成电荷，
     * 通过模数转换器芯片转换成电信号。CCD由许多独立的感光单位组成，通常以百万像素为单位。当CCD表面受到光照时，
     * 每个感光单位都会将电荷反映在组件上，所有的感光单位产生的信号加在一起，就构成了一幅完整的图像。CCD传感器以日本厂商为主导，
     * 全球市场上有90%被日本厂商垄断，索尼、松下、夏普是龙头。
     * >>CMOS（Complementary Metal-Oxide Semiconductor），互补性氧化金属半导体：主要是利用硅和锗做成的半导体，
     * 使其在CMOS上共存着带N(-)和P(+)级的半导体，这两个互补效应所产生的电流可以被处理芯片记录并解读成影像。
     * CMOS传感器主要以美国、韩国和中国台湾为主导，主要生产厂家是美国的OmnVison、Agilent、Micron，
     * 中国台湾的锐像、原相、泰视等，韩国的三星、现代。
     * <p>
     * 4.图像处理芯片 DSP （digital singnal processor）
     * DSP是CCM的重要组成部分，它的作用是将感光芯片获得的数据及时地快速地传递到中央处理器并刷新感光芯片，
     * 因此DSP芯片的好坏，直接影响画面品质，如：色彩饱和度、清晰度、流畅度等。
     * 如果sensor没有集成DSP，则通过DVP的方式传输到baseband芯片中（可以理解为外挂DSP），
     * 进入DSP的数据是RAW Data，采集到的原始数据。
     * 如果集成了DSP，则RAW Data会经过AWB、color matrix、lens shading、gamma、sharpness、AE和de-noise处理，
     * 最终输出YUV或者RGB格式的数据。
     *
     *
     * <p>
     * 总结:摄像头模组，光信号 -(传感器)> 电信号  -(A/D)> Raw data  -(DSP)>  rgb或yuv
     * <p>
     * 光学图像再同学半导体的图像传感器生成电学信号；
     * 电学信号由A/D转换器转化为数字图像信号；
     * 数字图像信号经由DSP处理，输出RGB或者YUV
     * <p>
     * --------------A/D转换----------------
     * 将模拟信号转换成数字信号的电路，称为模数转换器
     * （简称a/d转换器或adc,analog to digital converter）
     * <p>
     * A/D转换的作用是将时间连续、幅值也连续的模拟量转换为时间离散、幅值也离散的数字信号，因此，A/D转换一般要经过取样、保持、量化及编码4个过程。
     * 在实际电路中，这些过程有的是合并进行的，例如，取样和保持，量化和编码往往都是在转换过程中同时实现的。
     * <p>
     * <p>
     * ==================采样率================
     * 采样率，从连续的模拟信号中 转换为数字信号 的 频率
     * 比如采样率为 10kHz 就是说1秒内从模拟信号中采取 10k 个数字信号
     * 那么它的倒数就是0.1/1k，代表取一个数字信号所用的时间
     * 采样率越高代表 越接近 真实
     * <p>
     * 连续的光信号转化为连续的电信号，从连续的电信号中取样，取出raw data，输出给dsp
     * <p>
     * =================赫兹=========
     * 赫兹 hz 频率单位，指1秒内 "运动周期"的 次数
     * <p>
     * ============码率/比特率===========
     * 码率 = 比特率 = bit/s = bit per second = bps
     * 采样率*每个样本的bit = 码率
     * 清晰度高，每个样本的bit就大（更清晰）， 或者采样率高（更流畅）  =  视频更接近真实
     * <p>
     * 一个MP4的比特率就是文件字节数*8bit/ 视频长度
     * <p>
     * 采样率是1秒取多少个样点，码率是一秒钟所有样点占用内存的大小
     *
     *
     * ============主流采样方式============
     * 通常用的是YUV4:2:0的采样方式，能获得1/2的压缩率
     *
     *
     *
     *
     */
    void f2() {
    }


    /**
     * ===============yuv==================
     * YUV（Y'CbCr，Y'PbPr）和RGB都是颜色编码的方案，
     * Y代表亮度，UV代表色彩信息
     * yuv y表示亮度 u和v表示色差(u和v也被称为：Cb－蓝色差，Cr－红色差)，
     * b-blue r-red
     * u和v作用是描述影像色彩及饱和度
     * <p>
     * Y'UV最大的优点在于只需占用极少的带宽。
     * <p>
     * YUV数据有两种格式
     * 紧缩格式（packed formats）yuv数据聚集在一起的数组
     * 平面格式（planar formats）三个分量存储在不同的矩阵中（代表一种存储风格）
     *
     *
     *  YUV，分为三个分量，
     *  “Y”表示明亮度（Luminance或Luma），也就是灰度值；（从黑到白，所以黑白电视只要Y即可）
     *  而“U”和“V” 表示的则是色度（Chrominance或Chroma），
     *  作用是描述影像色彩及饱和度，用于指定像素的颜色。
     *  采样，光信号转换为数字信号
     *  主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0 （见drawable）
     *  1. YUV 4:4:4采样，每一个Y对应一组UV分量8+8+8 = 24bits,3个字节。
     *  2. YUV 4:2:2采样，每两个Y共用一组UV分量,一个YUV占8+4+4 = 16bits 2个字节。
     *  3. YUV 4:2:0采样，每四个Y共用一组UV分量一个YUV占8+2+2 = 12bits  1.5个字节。
     *  也就是一个y是一个像素点，每个y大小是8位（一个byte） u是8位，v是8位
     *  而YUV 4:2:2 是每两个y用一个uv ，所以一个y就是4位的u和v，
     *
     *
     * ========YUV420===============
     * 因为YUV420比较常用，（4个y共享一个u和一个v） 在这里就重点介绍YUV420。YUV420分为两种：YUV420p和YUV420sp
     * (格式见drawable)
     * 如图
     * YUV420p：又叫planer平面模式，Y ，U，V分别再不同平面，也就是有三个平面。
     * YUV420sp：又叫bi-planer或two-planer双平面，Y一个平面，UV在同一个平面交叉存储。
     * <p>
     * 根据uv的存储顺序不同
     * <p>
     * YUV420p 又细分：（这个是平面模式，所以yuv是存在三个数组中）
     * I420(又叫YU12): 安卓的模式。存储顺序是先存Y，再存U，最后存V。yyyyyyyyuuvv(4个y公用一个u和v)
     * YV12:存储顺序是先存Y，再存V，最后存U。yyyyyyyyvvuu
     * <p>
     * YUV420sp又分为 (这个是uv交错)
     * NV12:IOS只有这一种模式。存储顺序是先存Y，再UV交替存储。yyyyyyyyuvuv
     * NV21:安卓的模式。存储顺序是先存Y，再存U，再VU交替存储。yyyyyyyyvuvu
     * <p>
     * 所以一个yuv420图片大小计算的方法是
     * 一个像素大小= 1byte y + 0.25（2/8） byte的 u 和0.25byte的v =1.5byte
     * 所以 height*width*1.5byte就是这个帧的大小了
     *  <p>
     *
     *  常用的YUV存储（采样）格式（平面格式） 有I420（4:2:0）、YV12、IYUV等（具体的存储格式）
     *  4:4:4表示完全取样。
     *  4:2:2表示2:1的水平取样，垂直完全采样。(具体见drawable)
     *  4:2:0表示2:1的水平取样，垂直2：1采样。
     *  4:1:1表示4:1的水平取样，垂直完全采样。
     *  <p>
     *  DVD-Video是以YUV 4:2:0的方式记录，也就是我们俗称的I420
     *  <p>
     *  https://www.jianshu.com/p/e67f79f10c65（图片表示）
     *  <p>
     *
     *
     */
    void f3() {}


    /**
     * ===============视频编码============
     * yuv格式的视频还是很大，而且冗余信息很多，比如上一帧和这一帧只有一个像素点颜色不同，
     * 那么这一帧就不需要存其他像素点的信息了。
     * 所以要制定一套视频压缩（编码）标准是很有必要的。
     *
     * 提到视频编码标准，先介绍几个制定标准的组织
     * -----------ITU（国际电信联盟）-------------
     *  * ITU 国际电信联盟  International Telecommunication Union
     *  * VCEG video coding expert group 是ITU下的子组织（工作组）
     *
     *1865年5月17日，为了顺利实现国际电报通信，法、德、俄、意、奥等20个欧洲国家的代表在巴黎签订了《国际电报公约》，国际电报联盟（International Telegraph Union ，ITU）也宣告成立。
     * 随着电话与无线电的应用与发展，ITU的职权不断扩大。
     *
     * 1906年，德、英、法、美、日等27个国家的代表在柏林签订了《国际无线电报公约》。
     * 1932年，70多个国家的代表在西班牙马德里召开会议，将《国际电报公约》与《国际无线电报公约》合并， 制定《国际电信公约》，并决定自1934年1月1日起正式改称为“国际电信联盟” ，也就是现在的ITU。
     * ITU是联合国下属的一个专门机构，其总部在瑞士的日内瓦。
     *
     * ITU下属有三个部门，分别是ITU-R（前身是国际无线电咨询委员会CCIR）、ITU-T（前身是国际电报电话咨询委员会CCITT）、ITU-D
     * ITU-R 无线电通信部门
     * ITU-T 电信标准化部门
     * ITU-D 电信发展部门
     *
     *
     * ------------MPEG Moving Picture Expert Group（动态图像专家组）-------------
     *
     *
     * 除了ITU之外，另外两个和视频编码关系密切的组织，是ISO/IEC
     * ISO大家都知道，就是推出ISO9001质量认证的那个“国际标准化组织”。IEC，是“国际电工委员会”。
     *
     * 1988年，ISO和IEC联合成立了一个专家组，负责开发电视图像数据和声音数据的编码、解码和它们的同步等标准。
     * 这个专家组，就是大名鼎鼎的MPEG，Moving Picture Expert Group（动态图像专家组）。
     *
     *   ISO international organization for standardization  (国际标准化组织)
     *   IEC 国际电工委员会
     *   MPEG moving picture expert group 移动图像专家组，是iso/IEC下的一个工作组
     *   几百名成员组成，专门负责 音频视频 编码标准制定的工作
     *
     * -------------Video coding format(视频编码格式) /编码标准----------
     *
     * 三十多年以来，世界上主流的视频编码标准，基本上都是它们提出来的。
     * ITU提出了H.261、H.262、H.263、H.263+、H.263++，这些统称为H.26X系列，主要应用于实时视频通信领域，如会议电视、可视电话等
     *
     * ISO/IEC提出了MPEG1、MPEG2、MPEG4、MPEG7、MPEG21，统称为MPEG系列
     *
     * ITU和ISO/IEC一开始是各自捣鼓，后来，两边成立了一个联合小组，名叫JVT（Joint Video Team，视频联合工作组）
     *
     * JVT致力于新一代视频编码标准的制定，后来推出了包括H.264在内的一系列标准。
     *
     * 时间线见 video_encode_timeline.jpg
     *
     *
     *
     * 1.H.262 or MPEG-2 Part 2 = MPEG-2 Part 2 = H.262
     * <p>
     * 2.MPEG-4 Part 2 = 兼容H.263
     * <p>
     * 3.AVC Advanced Video Coding  = H.264 or MPEG-4 Part 10 = MPEG-4 AVC =H.264 AVC (这是MPEG组织和ITU-T组织联合定义的)
     * <p>
     * 4.High Efficiency Video Coding (HEVC) = H.265 and MPEG-H Part 2 = H.265 =  MPEG-H Part 2
     *
     *
     *  MPEG组织，他们制定了
     * · MPEG-1  （这个组织在1990年制定的第一个视频 和音频 压缩（编码）标准） 用于CD 、VCD
     * <p>
     * · MPEG-2 也叫"ISO/IEC 13818-2"   94年制定的第二个版本，用于DVD
     * <p>
     * · MPEG-3 本来是用于为HDTV（High Definition Television 高清电视）制定的压缩标准，
     * 但后来发现MPEG-2就足以满足需求，所以就合并到MPEG-2中了，其实没有MPEG-3的叫法
     * <p>
     * · MPEG-4 99年制定，用于网络流媒体
     * · MPEG-7 ？？？
     * · MPEG-21 正在开发？
     * · MPEG-H ？？
     * <p>
     * 每个MPEG-xxx都由很多部分（part）组成，每个部分定义了不同的规则
     * 比如MP3压缩规则是在MPEG-1 Layer 3 中定义的
     * 当然后来有改进 MPEG-1 or MPEG-2 Audio Layer III 是一种音频编码 ，有损压缩
     *
     *
     * ITU-T 是ITU下的一个部门，他下的一个叫VCEG的工作组制定了音频视频编码标准
     *  H.261
     *  H.262 就是MPEG-2 的视频部分
     *  H.263
     *  H.264 其实就是 MPEG-4 part 10 ,AVC 这个VCEG和MPEG一起制定的，只不过他们的叫法不一样，就像圣西罗和煤阿茶
     *  H.265 就是MPEG-H 的第二部分 ，他们内容一样，叫法不一样
     *
     *
     *
     *
     */
    void f4(){}



}
